{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./modules')\n",
    "\n",
    "###########################\n",
    "# Specify if the model being tested is 'mac' or 'spoc'\n",
    "pooling_type='mac'\n",
    "# Length of feature vectors\n",
    "len_features = 512\n",
    "###########################\n",
    "\n",
    "# For saving features\n",
    "features_parent_dir='./featuresTest'\n",
    "if not os.path.exists(features_parent_dir):\n",
    "    os.makedirs(features_parent_dir)\n",
    "features_db_path='featuresDb_' + pooling_type + '_images_real.npy'\n",
    "features_test_path='featuresTest_' + pooling_type + '_images_real.npy'\n",
    "\n",
    "# CSV file for train data \n",
    "csv_path_db_processed = '../real_images/df_final_all_resized_top14_folder_split_train.csv'\n",
    "# Images directory for train data\n",
    "imagesDir_db = '../real_images/train'\n",
    "# CSV file for test data\n",
    "csv_path_test_processed = '../real_images/df_final_test_top14.csv'\n",
    "# Images directory for test data\n",
    "imagesDir_test = '../real_images'\n",
    "\n",
    "#For saving results\n",
    "results_parent_dir = './results'\n",
    "results_dir='./' + pooling_type + '_base-shape/siamese-margin-01'\n",
    "if not os.path.exists(results_parent_dir+results_dir):\n",
    "    os.makedirs(results_parent_dir+results_dir)\n",
    "results_csv_path='/Test_Siamese_Top_1.csv'\n",
    "\n",
    "# If loading model weights...\n",
    "weights_path='../saved_models/mac-real-image-new-data-margin01_conv5_pca_32_1e-05_300_3_1600.h5'\n",
    "\n",
    "# Column of the csv being considered\n",
    "column_target = 'std_image'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Deep_Retrieval_Siamese_Architecture import deep_retrieval_siamese\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "\n",
    "batch_size=1\n",
    "## Load Deep Image Retrieval model\n",
    "print('Loading Deep Image Retrieval model...')\n",
    "model = deep_retrieval_siamese((224, 224,3), pooling_type)\n",
    "## Freeze all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[3].layers:\n",
    "    layer.trainable = False\n",
    "## Unfreeze some of the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[3].layers[-5:]:\n",
    "    layer.trainable = True\n",
    "print('Loading the weights...')\n",
    "model.load_weights(weights_path, )\n",
    "print('Done!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from modules_generating_results import compute_save_features\n",
    "np.random.seed(0)\n",
    "verbose=True\n",
    "#Train features\n",
    "features_database = compute_save_features(csv_path_db_processed,imagesDir_db,model,features_parent_dir,features_db_path,column_target,len_features,verbose)\n",
    "#Test features\n",
    "features_test = compute_save_features(csv_path_test_processed,imagesDir_test,model,features_parent_dir,features_test_path,column_target,len_features,verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find most similar images of test images in Db, save test statistics and display average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# number of top similar images retrieved \n",
    "no_top_similar_images = 5 \n",
    "#############################\n",
    "\n",
    "from modules_generating_results import compute_avg_precision\n",
    "from modules_generating_results import save_similar_images\n",
    "from modules_generating_results import compute_save_results\n",
    "import pandas as pd\n",
    "col_names=[\"query_image-name\",\"query_image\",\"retrieved_image\",\"average_precision\"]    \n",
    "df_database=pd.read_csv(csv_path_db_processed)\n",
    "df_test=pd.read_csv(csv_path_test_processed)\n",
    "compute_save_results(no_top_similar_images,col_names,features_database,features_test,df_database,df_test,column_target,\n",
    "                    results_parent_dir,results_dir,results_csv_path,save_images=False)\n",
    "\n",
    "# Compute average precision\n",
    "df_results=pd.read_csv(results_parent_dir+ results_dir+results_csv_path)\n",
    "scores=df_results[\"average_precision\"]\n",
    "print(\"Top \"+str(no_top_similar_images) + \" accuracy is \",np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(results_parent_dir+ results_dir+results_csv_path)\n",
    "# Load predictions\n",
    "preds=df_results[\"retrieved_image\"]\n",
    "# Load labels\n",
    "df_test_labels=pd.read_csv('../real_images/df_final_test_top14.csv')\n",
    "labels = df_test_labels[column_target]\n",
    "\n",
    "# Considering top similar images\n",
    "preds_top=[]\n",
    "for i in range(len(preds)):\n",
    "    if labels[i] in eval(preds[i]):\n",
    "        preds_top.append(labels[i])\n",
    "    else:\n",
    "        preds_top.append(eval(preds[i])[0])\n",
    "        \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels,preds_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
